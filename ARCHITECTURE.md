# ğŸ—ï¸ Architecture Overview

Detailed architecture and design decisions for AI Advisory.

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Terminal                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ CLI Command
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      cli.py (Typer App)                      â”‚
â”‚  â€¢ Parse arguments                                           â”‚
â”‚  â€¢ Validate token                                            â”‚
â”‚  â€¢ Orchestrate workflow                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                           â”‚
          â”‚ Level 1                                   â”‚ Level 2
          â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   models.query_all()    â”‚              â”‚   prompts.build_meta()  â”‚
â”‚  â€¢ Async HTTP calls     â”‚              â”‚  â€¢ Bundle responses     â”‚
â”‚  â€¢ Concurrent execution â”‚              â”‚  â€¢ Generate meta-prompt â”‚
â”‚  â€¢ Error handling       â”‚              â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                         â”‚
           â”‚                                         â”‚
           â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OpenRouter API                            â”‚
â”‚                https://openrouter.ai/api                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚          â”‚
       â–¼          â–¼          â–¼          â–¼          â–¼
    â”Œâ”€â”€â”€â”      â”Œâ”€â”€â”€â”      â”Œâ”€â”€â”€â”      â”Œâ”€â”€â”€â”      â”Œâ”€â”€â”€â”
    â”‚GPTâ”‚      â”‚CLUâ”‚      â”‚GEMâ”‚      â”‚DEEâ”‚ ...  â”‚KIMâ”‚
    â””â”€â”€â”€â”˜      â””â”€â”€â”€â”˜      â””â”€â”€â”€â”˜      â””â”€â”€â”€â”˜      â””â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Responses
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  display.py (Rich UI)                        â”‚
â”‚  â€¢ Format responses as panels                                â”‚
â”‚  â€¢ Show spinners during API calls                            â”‚
â”‚  â€¢ Handle user input for selection                           â”‚
â”‚  â€¢ Color-code success/error states                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Visual Output
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Terminal                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. ChatGPT (2.3s)                                   â”‚    â”‚
â”‚  â”‚ Response content...                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  Select responses: 1,3,5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. ChatGPT Evaluation (3.1s)                        â”‚    â”‚
â”‚  â”‚ Rating: 8/10, Agreement: ..., Consensus: ...        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Core Components

### 1. `cli.py` - Main Application

**Responsibilities:**
- Parse command-line arguments with Typer
- Validate and resolve API token
- Orchestrate the two-level workflow
- Handle user interaction

**Key Functions:**
- `ask()`: Main command handler
- Token resolution from env or flag
- Response selection prompt

**Design Decisions:**
- Used Typer for clean CLI with auto-generated help
- Single command (`ask`) keeps interface simple
- Synchronous orchestration with async API calls

---

### 2. `models.py` - API Communication

**Responsibilities:**
- Async HTTP requests to OpenRouter
- Concurrent model querying
- Error handling and timeout management
- Response parsing

**Key Functions:**
- `query_model()`: Single model query with error handling
- `query_all_models()`: Parallel execution with `asyncio.gather()`

**Design Decisions:**
- httpx for async HTTP (better than requests for concurrency)
- Individual try/except per model (failures don't cascade)
- 60-second timeout per request
- Structured response format (success, content, elapsed time)

**Error Handling:**
```python
try:
    # API call
except httpx.TimeoutException:
    # Timeout-specific error
except httpx.HTTPStatusError:
    # HTTP error with status code
except Exception:
    # Catch-all for unexpected errors
```

---

### 3. `prompts.py` - Meta-Prompt Generation

**Responsibilities:**
- Build Level 2 consensus evaluation prompts
- Format responses for evaluation
- Structure evaluation criteria

**Key Functions:**
- `build_meta_prompt()`: Creates comprehensive evaluation prompt

**Prompt Structure:**
```
Original Query: [user question]

Responses:
  1. [Model A response]
  2. [Model B response]
  ...

Evaluation Criteria:
  - Ratings (1-10)
  - Agreement analysis
  - Disagreement analysis
  - Pros & cons
  - Consensus answer
```

**Design Decisions:**
- Explicit evaluation criteria for consistent results
- Numbered responses for easy reference
- Includes original query for context

---

### 4. `display.py` - User Interface

**Responsibilities:**
- Rich terminal UI rendering
- Spinner animations during API calls
- Color-coded response panels
- User input handling

**Key Functions:**
- `display_response()`: Level 1 response panels (green/red)
- `display_evaluation()`: Level 2 evaluation panels (magenta)
- `get_selection()`: Interactive response selection
- `show_spinner()`: Loading animations

**Visual Elements:**
```python
# Green panel for success
Panel(content, border_style="green", title="1. ChatGPT (2.3s)")

# Red panel for errors
Panel(error, border_style="red", title="1. ChatGPT - ERROR")

# Magenta for evaluations
Panel(eval, border_style="magenta", title="1. ChatGPT Evaluation")
```

**Design Decisions:**
- Rich library for beautiful terminal output
- Color coding for quick visual scanning
- Elapsed time helps users understand performance
- Flexible selection (numbers or 'all')

---

### 5. `config.py` - Configuration

**Responsibilities:**
- Model registry (8 models with OpenRouter IDs)
- API endpoint configuration
- Token resolution logic

**Model Registry:**
```python
MODELS = [
    {"name": "ChatGPT", "id": "openai/gpt-4.1"},
    {"name": "Gemini", "id": "google/gemini-2.5-flash"},
    # ... 8 total
]
```

**Design Decisions:**
- Centralized model configuration
- Easy to add/remove models
- Name + ID mapping for display and API
- Token fallback: flag â†’ env var â†’ error

---

## ğŸ”„ Data Flow

### Level 1: Initial Query

```
1. User Input
   â†“
2. Token Resolution
   â†“
3. Create Messages Array: [{"role": "user", "content": query}]
   â†“
4. Async Query All Models (concurrent)
   â†“
5. Parse Responses (success/error for each)
   â†“
6. Display All Responses as Panels
   â†“
7. User Selects Responses (interactive)
```

### Level 2: Consensus Evaluation

```
1. Filter Selected Responses (successful only)
   â†“
2. Build Meta-Prompt with Selected Responses
   â†“
3. Create Meta-Messages Array
   â†“
4. Async Query All Models Again (concurrent)
   â†“
5. Parse Evaluations
   â†“
6. Display All Evaluations as Panels
```

---

## ğŸš€ Performance Characteristics

### Concurrency Model

- **Async I/O**: All API calls use asyncio
- **Parallel Execution**: `asyncio.gather()` for simultaneous requests
- **No Retries**: Failed requests fail fast (no doubled costs)

### Timing

Typical execution times:

| Operation | Time |
|-----------|------|
| Single model query | 1-5 seconds |
| Level 1 (8 concurrent) | 2-6 seconds |
| Level 2 (8 concurrent) | 3-8 seconds |
| Total workflow | 5-15 seconds |

### Resource Usage

- **Memory**: Minimal (<50MB typical)
- **Network**: 8 concurrent HTTP requests
- **CPU**: Low (I/O bound, not CPU bound)

---

## ğŸ”’ Security Considerations

### API Token Handling

- Never logged or displayed
- Environment variable preferred
- Flag option for flexibility
- Clear error if missing

### Input Validation

- User queries: No validation (sent as-is to models)
- Selection input: Validated range and format
- Token: Basic presence check

### Error Information

- API errors shown to user (for debugging)
- No sensitive data in error messages
- Detailed HTTP status codes included

---

## ğŸ¨ Design Patterns

### 1. **Async/Await Pattern**

```python
async def query_model(...):
    async with httpx.AsyncClient() as client:
        response = await client.post(...)
```

**Why:** Enables concurrent API calls without threads

### 2. **Structured Response Pattern**

```python
{
    "success": True/False,
    "name": "Model Name",
    "content": "...",
    "elapsed": 2.3,
    "error": "..." (if failed)
}
```

**Why:** Consistent interface for both success and failure

### 3. **Separation of Concerns**

- CLI orchestration (cli.py)
- API communication (models.py)
- Prompt generation (prompts.py)
- UI rendering (display.py)
- Configuration (config.py)

**Why:** Each module has single responsibility

### 4. **Fail-Fast with Graceful Degradation**

```python
try:
    result = await query_model()
except Exception as e:
    # Return error structure, don't crash
    return {"success": False, "error": str(e)}
```

**Why:** One model failure doesn't affect others

---

## ğŸ“¦ Dependencies

### Direct Dependencies

| Package | Purpose | Version |
|---------|---------|---------|
| typer | CLI framework | >=0.9 |
| httpx | Async HTTP | >=0.25 |
| rich | Terminal UI | >=13.0 |

### Transitive Dependencies

- click (via typer) - CLI utilities
- anyio (via httpx) - Async compatibility
- certifi (via httpx) - SSL certificates
- h11 (via httpx) - HTTP/1.1 protocol

**Total Size:** ~5MB installed

---

## ğŸ”„ Extension Points

### Adding New Models

```python
# In config.py
MODELS.append({
    "name": "NewModel",
    "id": "provider/model-id"
})
```

### Custom Prompts

```python
# In prompts.py
def build_custom_prompt(query, responses):
    # Custom prompt logic
    return prompt
```

### Alternative Display

```python
# Create new display function
def display_json(responses):
    import json
    print(json.dumps(responses, indent=2))
```

### Caching Layer

```python
# Add to models.py
CACHE = {}

async def query_model_cached(model_id, messages):
    cache_key = hash((model_id, str(messages)))
    if cache_key in CACHE:
        return CACHE[cache_key]
    result = await query_model(model_id, messages)
    CACHE[cache_key] = result
    return result
```

---

## ğŸ§ª Testing Strategy

### Unit Tests (Future)

- `test_config.py`: Token resolution logic
- `test_prompts.py`: Meta-prompt generation
- `test_models.py`: Response parsing (mocked API)

### Integration Tests (Future)

- End-to-end workflow with mock API
- Error handling scenarios
- User input validation

### Manual Testing

Current approach:
1. Test with real API (small queries to minimize cost)
2. Verify all 8 models respond
3. Test error scenarios (invalid token, network errors)
4. Test selection logic (numbers, 'all', invalid input)

---

## ğŸ“ˆ Future Improvements

### Performance

- [ ] Response streaming for real-time output
- [ ] Caching to reduce API costs
- [ ] Parallel Level 1 and Level 2 (pipeline)

### Features

- [ ] Model selection (subset of 8)
- [ ] Custom evaluation criteria
- [ ] Export results (JSON/Markdown)
- [ ] History tracking
- [ ] Configuration file

### User Experience

- [ ] Interactive TUI (textual)
- [ ] Response comparison view
- [ ] Progress bars per model
- [ ] Syntax highlighting for code responses

### Infrastructure

- [ ] Unit tests
- [ ] CI/CD pipeline
- [ ] Docker image
- [ ] Pre-commit hooks

---

## ğŸ¯ Architectural Decisions

### Why OpenRouter?

- âœ… Single API for multiple providers
- âœ… Unified pricing and billing
- âœ… OpenAI-compatible interface
- âœ… No need for multiple API keys

### Why Async Instead of Threads?

- âœ… Better for I/O-bound operations
- âœ… More efficient resource usage
- âœ… Cleaner error handling
- âœ… Python async ecosystem maturity

### Why No Database?

- âœ… Simple CLI tool
- âœ… Stateless operation
- âœ… Easier installation
- â“ May add optional caching later

### Why Rich Instead of Click?

- âœ… Beautiful colored output
- âœ… Panels, tables, progress bars
- âœ… Better user experience
- âœ… Works well with Typer (uses click underneath)

### Why No Retries?

- âœ… Avoid doubled API costs
- âœ… Faster failure feedback
- âœ… User can retry entire query if needed
- â“ May add optional retry with exponential backoff

---

## ğŸ“ Code Metrics

### Lines of Code

| File | Lines | Purpose |
|------|-------|---------|
| cli.py | ~80 | Main application |
| models.py | ~70 | API communication |
| prompts.py | ~40 | Prompt generation |
| display.py | ~90 | UI rendering |
| config.py | ~30 | Configuration |
| **Total** | **~310** | Core functionality |

### Complexity

- **Cyclomatic Complexity**: Low (mostly linear flow)
- **Dependency Depth**: 1 level (no nested dependencies)
- **Function Size**: Small (10-40 lines average)

---

This architecture prioritizes:
- **Simplicity**: Easy to understand and modify
- **Reliability**: Robust error handling
- **Performance**: Concurrent API calls
- **User Experience**: Beautiful terminal output
- **Extensibility**: Easy to add models/features
